\documentclass[12pt,a4paper,oneside]{extarticle}
\usepackage{fontspec,xltxtra,xcolor}
\usepackage{microtype}
\usepackage{polyglossia}
\usepackage[hidelinks]{hyperref}
\usepackage[top=0.75in, bottom=0.75in, left=0.75in, right=0.75in]{geometry}
\usepackage[style=gost-footnote,sortlocale=ru,natbib=true]{biblatex}
\setdefaultlanguage{russian}
\setotherlanguages{english,greek,churchslavonic} % set as "other" so English hyphenation active
\def\hyph{-\penalty0\hskip0pt\relax}

\defaultfontfeatures{Mapping=tex-text}
\setromanfont{Linux Libertine O}
\setsansfont{Linux Biolinum O}
\newfontfamily\churchslavonicfont[Script=Cyrillic,HyphenChar=_]{Ponomar Unicode}
\newfontfamily{\cyrillicfonttt}{Linux Libertine O}
\newfontfamily\greekfont[Script=Greek]{Old Standard}
\providecommand{\keywords}[1]{\textbf{Ключевые слова}: #1}

\bibliography{hyphenation}

\title{Автоматизация слогоделения и переноса строки в церковнославянских текстах}
\author{А.~А.~Андреев\thanks{Андреев Александр Андреевич -- магистр богословия, магистр экономических наук, аспирант кафедры Церковно-практических дисциплин Санкт-Петербургской духовной академии; \url{aleksandr.andreev@gmail.com}.} \and М.~П.~Крутиков\thanks{\url{pgmmpk@gmail.com}}}
\date{\vspace{-1em}}  % hack to remove some wasted vertical blank space

\begin{document}
\clubpenalty=10000
\widowpenalty=10000
\interfootnotelinepenalty=0
\maketitle

\begin{abstract}
Решение проблемы автоматизации слогоделения и переноса строки
(\textenglish{hyphenation}) в системе \TeX{} было впервые предложено в 1983~г.
Ф.~Льянгом. Однако до сих пор метод Льянга не применялся к
церковнославянским текстам в кодировке Юникод. Тем не менее проблема
автоматизации переноса строки и слогоделения является актуальной при
верстки текстов. В данной статье формулируются правила переноса строки
для церковнославянского языка и предлагается автоматизированное решение,
основанное на методе Льянга. Авторы описывают процедуру разработки
шаблонов переноса (\textenglish{hyphenation patterns})
и предлагают методы оценки их эффективности.
\end{abstract}

\keywords{типографика, морфология, слогоделение, компьютерные алгоритмы, Юникод}

\section{Введение}

При наборе церковнославянского текста на компьютере, пользователь сталкивается с проблемой переноса строки. Необходимость переноса строки особенно актуальна при наборе богослужебных текстов, т.~к. богослужебные книги обычно форматируются с выравниванием по ширине (\textenglish{justified alignment}). В этом случае наличие сложных, многослоговых слов приводит к нежелательному растягиванию пробелов между словами. Перенос строки помогает выравнять текст по ширине и сократить ширину пробелов.

При современном типографском наборе, перенос строки обычно выполняется программой верстки текста автоматически, используя алгоритм переноса (\textenglish{hyphenation algorithm}), который зависит от языка текста и культурных особенностей. Однако в современных программах верстки текста нет алгоритма переноса для церковнославянского языка\footnote{В прочем пакеты для набора церковнославянских текстов в системе \TeX{} HipTeX и CSTeX поставлялись с шаблонами переносов в устаревшей кодировке UCS, однако никаких описаний словарей или методологии создания шаблонов мы найти не смогли.}. Очевидно, что пользователь не может просто применить алгоритм переноса для русского языка к церковнославянскому тексту, т.~к. церковнославянский язык имеет свой, отличный от русского языка набор букв. Также, как мы покажем, правила переноса в церковнославянском языке несколько отличаются от правил современного русского языка.

В данной статье мы описываем правила переноса для современного церковнославянского языка, т.~е. языка <<синодального извода>>, который используется в богослужебных текстах Русской православной церкви сегодня. Далее мы описываем пути решения проблемы автоматизации переноса для системы верстки текста \TeX{}, для чего авторами созданы соответствующие пакеты. При этом авторы смогли не только создать необходимые шаблоны переносов, но и разработать и применить методы тестирования их эффективности.

\section{Правила слогоделения в церковнославянском языке}

Перенос строки в церковнославянском языке, как и в русском языке, должен происходить на границе слогов. Однако правила слогоделения подробно не описаны ни в одном учебном пособии по церковнославянскому языку. Лишь в некоторых учебниках приводятся упоминания, что перенос строки должен производиться по таким же правилам, как и в русском языке. Просмотрев издания Московской и Санкт-Петербургской синодальных типографий, а также издания Киево-Печерской лавры за 1840--1917~гг., мы пришли к выводу, что, с учетом ряда дополнительных требований, связанных с особенностями церковнославянской орфографии, перенос строки в церковнославянских текстах должен следовать правилам слогоделения для русского языка в дореформенной орфографии. Эти дореформенные правила подробно описаны в классическом пособии Я.~К. Грота <<Русское правописание>>\autocite[][]{grot1902}. Опираясь на указанные Я.~К. Гротом правила для русского языка, мы приводим правила слогоделения для церковнославянского языка.

\begin{table}[h]
\centering
\caption{Примеры морфологического разбора церковнославянских слов \label{one}}
\begin{tabular}{ll}
Правильно   	& 	Неправильно \\
\hline
\textchurchslavonic{свѣ́т-лый} & \textchurchslavonic{свѣ́-тлый} \\
\textchurchslavonic{грѣ́ш-ный} & \textchurchslavonic{грѣ́-шный} \\
\textchurchslavonic{же́н-скїй}	& \textchurchslavonic{же́-нскїй}, \textchurchslavonic{же́нс-кїй} \\
\textchurchslavonic{вѣст-во-ва́-нї-е} & \textchurchslavonic{вѣ-ство-ва́-нї-е} \\
\textchurchslavonic{дѣ́тель-ство-ва} &	\textchurchslavonic{дѣ́тельст-во-ва}, \textchurchslavonic{дѣ́тельс-тво-ва} \\
\hline
\end{tabular}
\end{table}

Для простых слов, следует сначала правильно выделить корень слова и отделить от корня суффиксы и окончания, как указано в примерах в Таблице~\ref{one}. Согласные внутри суффиксов (напр., \textchurchslavonic{-ство}, \textchurchslavonic{-скїй}) не должны быть разделяемы. Если суффикс начинается с согласной, то он может переноситься на новую строку, как в словах: \textchurchslavonic{же́н-скїй}, \textchurchslavonic{за-блꙋ́жд-шихъ}, \textchurchslavonic{кро́т-кїй}, \textchurchslavonic{свѣ́т-лый}, \textchurchslavonic{се́рд-це}, \textchurchslavonic{скве́р-ный}, \textchurchslavonic{тѣ́с-ный} (но: \textchurchslavonic{при́-сный}), \textchurchslavonic{чис-ло̀} (но: \textchurchslavonic{ма́-сло}), \textchurchslavonic{мо-ли́-тва} (но: \textchurchslavonic{клѧ́т-ва}).

Группы согласных, стоящие вне суффикса разделяются по следующему принципу. Если стечение согласных начинается с плавного (\textchurchslavonic{л}, \textchurchslavonic{р}), носового (\textchurchslavonic{н}, \textchurchslavonic{м}) или шипящего (\textchurchslavonic{ш}, \textchurchslavonic{щ}, \textchurchslavonic{ж}, \textchurchslavonic{ч}), то буква, записывающая такой звук, остается на строке, а следующие за ней слогласные, формирующие слог, переносятся: \textchurchslavonic{во́л-ны}, \textchurchslavonic{го́р-дость}, \textchurchslavonic{до́н-деже}, \textchurchslavonic{кам-па́нъ}, \textchurchslavonic{мы́ш-ца}, \textchurchslavonic{ѹ҆мерщ-вле́й}, \textchurchslavonic{лꙋ́ч-ше}. К носовым следует также относить комбинации согласных \textchurchslavonic{-гг-}, \textchurchslavonic{-гк-}, \textchurchslavonic{-гх-} в словах иностранного происхождения, в которых \textchurchslavonic{г}, в соотвествии с правилами греческого языка, читается как \textchurchslavonic{н}. Так мы имеем: \textchurchslavonic{а҆г-кѵ́-ра}, \textchurchslavonic{а҆гаѳаг-ге́лъ} (но: \textchurchslavonic{а҆-гге́й}), \textchurchslavonic{паг-ха́-рїй}).

Если стечение согласных начинается с другого звука, например, с губных или зубных, то все согласные стечения переносятся на следующую строку, как в случаях \textchurchslavonic{сре-бро̀}, \textchurchslavonic{га-врїи́лъ}, \textchurchslavonic{є҆-фре́мъ}, \textchurchslavonic{не-пщева́ти}. В особенности не следует разделять согласные после \textchurchslavonic{с}: \textchurchslavonic{па́-сха} (неправильно: \textchurchslavonic{па́с-ха}), \textchurchslavonic{пе-ска̀} (а не \textchurchslavonic{пес-ка̀}), \textchurchslavonic{при́-снѡ}, \textchurchslavonic{го-спо́день}, но: \textchurchslavonic{чис-ло̀}. Также не следует разделять сочетания согласных, в которых происходит смягчение: \textchurchslavonic{-мл-}, \textchurchslavonic{-бл-}, \textchurchslavonic{-вл-}, \textchurchslavonic{-пл-}, \textchurchslavonic{-жд-}: \textchurchslavonic{зе-млѧ̀}, \textchurchslavonic{до́-блїй}, \textchurchslavonic{и҆зба-вле́нїе} (но: \textchurchslavonic{і҆а́кѡв-лю}), \textchurchslavonic{ме-ждꙋ̀}.

Правильное разделение стечений согласных является сложным нюансом при слогоделении; в остальных случаях действуют достаточно простые правила, похожие на соответствующие правила в русском языке. Согласная, стоящая между двумя гласными, начинает новый слог: \textchurchslavonic{мо-на́-си}, \textchurchslavonic{мо-лѧ́-ще}; две одинаковые согласные разделяются: \textchurchslavonic{а҆м-мꙋ́нъ}, \textchurchslavonic{а҆́н-на}, \textchurchslavonic{ва́с-са}; когда одна согласная отделена от другой согласной ерем, то слог начинается после еря: \textchurchslavonic{вель-мѝ}, \textchurchslavonic{де́нь-ги}. Две стоящие подряд гласные разделяются, за исключением диграфа \textchurchslavonic{ᲂу}, который никогда не разделяется: \textchurchslavonic{а҆-а-рѡ́нъ}, \textchurchslavonic{кле-о́-па}, \textchurchslavonic{ѹ҆́-ме}. Наконец буква \textchurchslavonic{ѵ} в тех случаях, когда она читается как \textchurchslavonic{в}, не отделяется от предшествующей ей гласной, если за ней следует согласная: \textchurchslavonic{а҆́ѵ-гꙋстъ}, \textchurchslavonic{є҆ѵ-ге́-нїй} (но: \textchurchslavonic{ле-ѵі́тъ}, \textchurchslavonic{на-ѵи́нъ}).

Отдельные правила относятся к слогоделению сложных слов, состоящих из нескольких корней или из префикса (приставки) и корня. В этих случаях необходимо разделить слово по слогам так, чтобы сохранить структуру корней и префикса, т.~е. чтобы согласные, принадлежащие корню не были отнесены к префиксу, и наоборот. При этом разделение сложного слова на корни и префиксы может нарушать правила слогоделения для простых слов, указанные выше. Так следует писать: \textchurchslavonic{и҆с-кꙋ-пи́лъ}, \textchurchslavonic{и҆с-по-вѣ́-да-нї-е} (но \textchurchslavonic{и҆-скра̀}, \textchurchslavonic{и҆́-сти-на}); \textchurchslavonic{вос-кли́к-нꙋть} (но \textchurchslavonic{во-скре-се́-нї-е}); \textchurchslavonic{со-зва̀} (а не \textchurchslavonic{соз-ва̀}); \textchurchslavonic{под-но́-жї-е}, \textchurchslavonic{под-кло-ни́-ти} (но  \textchurchslavonic{по́-двигъ}, \textchurchslavonic{по-дра-жа́-ти}); \textchurchslavonic{по-зна̀}, \textchurchslavonic{по́-мнити}; \textchurchslavonic{рас-ка́-ѧ-нї-е}; наконец, \textchurchslavonic{без-ꙋ́м-ный}, \textchurchslavonic{раз-ꙋ́м-нѡ} (в этих случаях в церковнославянском языке часто сохраняется ер в конце префикса, напр. при написании \textchurchslavonic{без̾-ꙋ́м-ный}). Однако если после префикса выпала согласная, относящаяся к корню слова, то гласная, следующая за префиксом не может начинать слога; так следует переносить \textchurchslavonic{ѡ҆-би-та́-ти} (а не \textchurchslavonic{ѡ҆б-и-та́-ти}), \textchurchslavonic{и҆-зы́-де} (а не \textchurchslavonic{и҆з-ы́-де}).

Теперь перейдем к ряду правил, касающихся непосредственно церковнославянской орфографии. В словах, в которых присутствуют сокращения с титлом или буквенным титлом, нельзя разделять внутри записанного под титлом сокращения, т.~е. нельзя писать \textchurchslavonic{а҆́г-г҃ли}, \textchurchslavonic{воскрⷭ҇-ный}. Обзор изданий церковнославянских богослужебных книг за 1840--1917~гг. показал, что разделение на слоги возможно только: при отделении префикса от сокращенного корня (напр., \textchurchslavonic{во-скрⷭ҇лъ}, \textchurchslavonic{все-чⷭ҇тно́-е}, \textchurchslavonic{пре-чтⷭ҇а-ѧ} и даже \textchurchslavonic{пре-чⷭ҇та-ѧ}); перед гласной, предшествующей сокращенному стечению (напр., \textchurchslavonic{а҆р-ха́гг҃лъ}, \textchurchslavonic{і҆-ерⷭ҇ли́мъ}); или после гласной или еря, начинающих следующий за сокращенным стечением слог (\textchurchslavonic{млⷭ҇рдї-е}, \textchurchslavonic{а҆пⷭ҇ль-скїй}, \textchurchslavonic{мч҃ни-ка}; но \textchurchslavonic{мч҃нка}).

В русском языке слог, состоящий из одной гласной, находящейся в начале или в конце слова, не может быть перенесен (так, неправильными были бы переносы в русских словах \emph{и-мя}, \emph{тво-ё}). Однако в церковнославянских текстах синодальной эпохи наблюдается перенос после слогов \textchurchslavonic{ѡ҆-}, \textchurchslavonic{ѿ-}, и \textchurchslavonic{ᲂу҆-}, находящихся в начале слова, ввиду того, что они являются префиксами. Так допускаются переносы \textchurchslavonic{ѡ҆-свѧще́нїе}, \textchurchslavonic{ѿ-вале́нъ}, \textchurchslavonic{ѹ҆-дивлѧ́ѧ}.  Другие однобуквенные слоги в начале слова не следует отделять и оставлять на предыдущей строке, равно как не следует переносить однобуквенный слог в конце слова (так, не следует переносить \textchurchslavonic{є҆-вре́и} или \textchurchslavonic{є҆вре́-и}).

\section{Разработка автоматизации слогоделения}

\subsection{Алгоритм слогоделения \TeX{}}

Проблема правильного переноса строки существует столько же, сколько и искусство печатного набора текста. О ней упоминается в первом пособии по типографике, \textenglish{Mechanick Exercises} Джозефа Моксона (1683~г.). С разработкой компьютерной типографики в середине XX~в. появляются и первые попытки автоматизированного решения проблемы переноса строки. Изначально были выявлены два возможных подхода: словарный и логический. Однако при ограничениях оперативной памяти и скорости процессора, словарный подход являлся неэффективным. С другой стороны, на практике оказывается, что слишком трудно написать список всех правил, что требуется для логического подхода.

Уникальное решение проблемы автоматизации переноса строки предложил Франклин Льянг\autocite[][]{liang1983}. Это решение, известное как Алгоритм Кнута--Льянга, впоследствии стало стандартным в компьютерной типографике, и применяется не только в системе верстки текста \TeX{}, для которой оно было изначально разработано Льянгом, но и в других программах\autocite[Первое описание системы \TeX{} см. ][]{knuth1979}. Алгоритм Кнута--Льянга основан на идее шаблонов слогоделения (\textenglish{hyphenation pattern}). Каждый такой шаблон записывает последовательность символов (строку), предоставляющую какую-то информацию о возможном слогоделении. Нечетная цифра указывает на место возможного деления. К примеру, чтобы указать, что слогоделение возможно в английском языке перед суффиксом \emph{-tion}, записывает шаблон \verb+1tion+. Однако такие шаблоны могут выдавать ошибочные результаты, например шаблон \verb+1tion+ неправильно делит английское слово \emph{cat-ion}. Для таких исключений алгоритм вводит запрещающие шаблоны (\textenglish{inhibiting pattern}). Места запрета слогоделения в запрещающих шаблонах указаны четными цифрами. К примеру, для запрета слогоделения перед \emph{tion} в слове \emph{cation} можно ввести запрещающий шаблон \verb+ca2tion+. Но запрещающие шаблоны могут, в свою очередь, запретить вполне допустимые деления в других словах, так, шаблон \verb+ca2tion+ запретит перенос в слове \emph{ap-pli-ca-tion}. Для этого слова вводится разрешающий шаблон следующего уровня, например шаблон \verb+lica3tion+. При заданных шаблонах, для того, чтобы разделить слово на слоги, алгоритм разбивает данное слово на группы символов (\textenglish{character clusters}) и ищет соответствующие этим группам шаблоны, выбирая шаблон с большей по величине цифрой. В итоге, места между группами, в которых стоит нечетная цифра, являются возможными местами разделения на слоги. В качестве примера, английскому слову \emph{hyphenation} подходят заданные шаблоны \verb+hy3ph+ \verb+he2n+ \verb+hena4+ \verb+hen5at+ \verb+1na+ \verb+n2at+ \verb+1tio+ \verb+2io+, которые в соединении дают результат \verb+hy3phe2n5a4t2ion+, соответствующий правильному слогоделению \emph{hy-phen-ation}\autocite[См. подробнее ][pp.~5--6, 35--40.]{liang1983}.

Следующим достижением Льянга было решение проблемы создания словаря шаблонов. Для автоматизации этой задачи, исследователь написал программу \verb+PATGEN+ (\emph{pattern generator} = генератор шаблонов), которая создает <<оптимальный>> перечень шаблонов из заданного словаря разделенных по слогам слов. Шаблоны подбираются итеративным подходом. Сначала программа просматривает словарь и выбирает разрешающие шаблоны. В последующих итерациях выбираются запрещающие, затем опять разрешающие шаблоны, с учетом шаблонов, выбранных в предыдущих итерациях. Этот процесс продолжается, пока не будут учтены все возможные слогоделения в словаре. При этом нужен некий критерий для отбора возможных шаблонов. С учетом того, что любой шаблон может сделать некое количество правильных слогоделений (что обозначается переменной $good$) и некое количество ошибочных слогоделений (что обозначается переменной $bad$), его эффективность может быть расценена как $efficiency = good / (1 + bad)$. При той или иной итерации отбираются шаблоны, чья эффективность превышает некий заданный порог, что выражается формулой

\begin{equation}
\label{eff_formula}
good * good\_wt - bad * bad\_wt \geq threshold
\end{equation}

\noindent где параметры $good\_wt$ и $bad\_wt$ устанавливаются для каждой итерации. На самом деле, такой подход является не больше чем ловким эвристическим устройством. Параметры $good\_wt$, $bad\_wt$ и $threshold$ Формулы~\ref{eff_formula} для каждой итерации подбираются методом проб и ошибок, и за ними нет никакого теоретического обоснования\autocite[Ср.: <<We do not have any theoretical justification for these parameters; they just seem to work well>>.][p.~36]{liang1983}. Так как по построению алгоритм генерирует все шаблоны, необходимые для того, чтобы правильно определить все указанные в заданном словаре слогоделения (для этого при последней итерации устанавливается $threshold = 1$ и $bad\_wt \rightarrow \infty$), единственным критерием, которым руководствуется разработчик шаблонов при выборе параметров является количество дискового пространства, которое занимает созданный словарь шаблонов.

\subsection{Применение Алгоритма Кнута--Льянга к другим языкам}

Алгоритм Кнута--Льянга был изначально предложен только для английского языка, который удобен тем, что записывается ограниченным количеством символов. Впоследствии, возможности \TeX{} были расширены созданием дополнительных кодовых таблиц\autocite[Кодировка \textenglish{Extended \TeX{} Font Encoding Scheme} (ET). См. ][]{ferguson1990}. Одновременно П.~Брейтенлохнер написал расширенную программу \verb+PATGEN2+\autocite[См. описание в пособии ][]{patgen2}, которая была успешно применена к созданию, например, шаблонов для древнегреческого языка\autocite[][]{haralambous1992}. С созданием стандарта Юникод в 1991~г., подход с разработкой альтернативных 8-битных кодировок потерял свою актуальность. Д.~Антош и  П.~Сойка разработали программу \texttt{OPatGen} ($\Omega$ \emph{pattern generator}), которая поддерживает Юникод и позволяет работать с большими алфавитами\autocite[][]{sojka2003}. Однако на данный момент она значительно устарела. Для разработки шаблонов для церковнославянского языка потребовалась новая программа, написанная на  высокоуровневом языке программирования. В этих целях М.~П. Крутиков разработал на языке \verb+Python+ программу \verb+pypatgen+\footnote{Описание и инструкции по пользованию см. \url{https://github.com/pgmmpk/pypatgen/}.}. Простота реализации и использование языка высокого уровня открывают возможности для внесения последующих изменений в исходный код с целью дальнейшего развития инструментария.

\section{Создание шаблонов для церковнославянского языка}

Как мы уже отметили, проблема экономии процессорного времени и оперативной памяти, с которой столкнулся Льянг, потеряла свою актуальность. Однако Алогритм Кнута--Льянга не претерпел значительных изменений за прошедшие 30~лет, и продолжает быть широко применимым и сегодня, не смотря на попытки разработать более современные подходы к автоматизированному слогоделению, использующие либо нейронные сети\autocite[К примеру, ][]{smrz1996}, либо условные случайные поля\autocite[К примеру, см. ][]{trogkanis2010}. Живучесть алгоритма объясняется тем, что шаблоны, сгенерированные достаточно простым вычислительным методом, могут правильно угадать слогоделения и в тех словах, которые не вошли в первоначальный словарь. С учетом этой задачи, эффективным должен быть признан такой набор шаблонов, который с большой точностью может быть применен к словам, не вошедшим в наш изначальный словарь. В этом разделе мы опишем процедуру создания шаблонов используя программу \verb+pypatgen+, а в следующем разделе -- примененный нами метод оценки эффективности шаблонов.

\subsection{Генерирование шаблонов}

Процедура создания шаблонов для \TeX{} происходит в следующей последовательности. Для начала был подготовлен словарь церковнославянских слов. В этих целях мы выбрали из словаря, содержащего все слова, встречающиеся в корпусе современных богослужебных текстов\footnote{Этот полный словарь содержит в совокупности $134.392$ слова.}, те, которые отвечают за 90\% случаев употребления слова. К этому списку слов были добавлены случайно выбранные имена собственные из Требника, а также технические термины из церковнославянского раздела Общего хранилища данных о локалях (\textenglish{Common Locale Data Repository}, CLDR)\footnote{См. \url{http://cldr.unicode.org/}.}. В итоге мы получили словарь, содержащий $17.525$ церковнославянских слов, которые затем были разбиты по слогам вручную.

Далее над этим словарем был запущен алгоритм генерирования шаблонов используя программу \verb+pypatgen+ (версия 0.2.9). Параметры $good\_wt$, $bad\_wt$ и $threshold$ Формулы~\ref{eff_formula} были установлены в соответствии с результатами процедуры оценки эффективности шаблонов, которая описывается в следующем разделе. В результате мы получили файл \verb+raw_patterns.txt+, содержащий сырые шаблоны и файл \verb+err_raw_patterns.txt+, содержащий исключения, т.~е. слова, которые не могут быть правильно разделены на слоги используя сгенерированные шаблоны. Эти исключения возникают в основном за счет того, что мы, в целях обобщения шаблонов, ограничиваем их длину. Таким образом список исключений содержит много однокоренных слов с <<длинными>> корнями, равно как и слов с <<необычными>> суффиксами, к примеру:

\begin{center}
\begin{churchslavonic}
\begin{tabular}{l}
бо-лѣ́-зней \\
бо-лѣ́-знемъ \\
бо-лѣ́-знен-нѡ \\
бо-лѣ́-знен-ны-ѧ \\
бо-лѣ́-зни \\
\end{tabular}
\end{churchslavonic}
\end{center}

\noindent Такие слова могут быть заменены одним шаблоном (в данном случае, шаблоном \textchurchslavonic{.болѣ́7зн}), что было сделано вручную для всех слов в списке исключений. В результате мы получаем файл \verb+root_patterns.txt+, который содержит перечень <<длинных>> шаблонов.

На следующем этапе нам необходимо добавить запрещающие шаблоны для случаев, где перенос абсолютно недопустим: перед диакритическими знаками и в некоторых других комбинациях символов. С этой целью мы прописываем шаблоны, запрещающие:

\begin{enumerate}
\item перенос внутри диграфа \textchurchslavonic{ᲂу}, который может кодироваться в Юникоде и как \verb!U+1C82 U+0443!, и как \verb!U+043E U+0443!;
\item перенос перед выносными символами ударения и придыхания, перед кендемой, титлом, и выносными буквами\autocite[Полный перечень символов вместе с их кодовыми точками в Юникоде, а также полный перечень возможных слов с титлом или буквенными титлами см. ][]{utn41};
\item перенос перед символом ерок (\verb!U+2E2F!) и перед буквами ер (\verb!U+044A!) и ерь (\verb!U+044C!);
\item перенос вокруг символов паерк (\verb!U+A67F!) и кавыка (\verb!U+A67E!).
\end{enumerate}

Получив на данном этапе полный перечень шаблонов слогоделения, мы далее создаем на его основе перечень шаблонов переноса строки. Разница заключается в том, что при слогоделении возможно отделение однобуквенного слога (напомним пример \textchurchslavonic{є҆-вре́-и}), однако переносить допускается только однобуквенные слоги \textchurchslavonic{ѡ҆-} и \textchurchslavonic{ѿ-} и диграф \textchurchslavonic{ᲂу҆-}. Так как любой начальной гласной в современном церковнославянском языке обязательно следует символ придыхания, мы не можем ограничиться заданием параметров \verb+lefthyphenmin+ и \verb+righthyphenmin+, отвечающих за минимальное количество символов, допустимых для переноса в начале или конце слова. Поэтому мы вручную прописываем шаблоны, запрещающие перенос одной буквы в начале и конце слов, за исключением допустимых для переноса слогов.

Наконец на последнем этапе мы учитываем проблему нормализации текста, закодированного в Юникоде. Некоторые комбинации букв с диакритическими знаками закодированы в Юникоде на отдельных кодовых точках (к примеру, буква \emph{й}). Такие буквы имеют два возможных, канонически тождественных представления; для решения проблемы взаимодействия этих представлений существует Алгоритм нормализации Юникода (\textenglish{Unicode Normalization Algorithm})\autocite[Подробности см. ][]{tr15}. Все словоформы в нашем первоначальном словаре были представлены в Нормализированной форме C (\textenglish{Normal Form C}). Теперь мы создаем в необходимых случаях соответствующие представления в Нормализированной форме D (\textenglish{Normal Form D}). На этом этапе мы также учитываем наличие других возможных двухсмысленных представлений\autocite[Специфику нормализации церковнославянского текста см. в работе ][]{utn41}. В итоге мы получаем перечень, содержащий $14.378$ шаблонов и $18$ исключений, который теперь может быть загружен в \TeX{}.

\subsection{Анализ эффективности шаблонов}

По построению, созданные шаблоны для \TeX{} будут давать правильный перенос строки для всех слов, включенных в словарь, использованный для создания шаблонов. Остается ответить на вопрос, насколько эти шаблоны полезны для слогоделения других слов. В своей диссертации Льянг также работал с относительно небольшим словарем и проверил его на нескольких текстах, содержащих новые слова. Отметив, что алгоритм хорошо справляется со многоми новыми словами, он однако не дал никаких количественных оценок. Многие разработчики шаблонов либо используют достаточно полные словари (и при этом задача обобщения на новые слова не актуальна), либо создают шаблоны вручную, если правила переноса языка достаточно просты. Таким образом, насколько нам известно, какие-то попытки количественного тестирования шаблонов \TeX{} ранее не предпринимались.

В целях такого тестирования мы использовали метод перекрестной проверки (\textenglish{cross-validation}). Изначальный словарь разделенных по слогам слов $D$ делиться на $N$ равных по количеству слов разделов $d$, так что $D = \cup_{i = 1}^{N} d_i$. Далее отбираются $N$ наборов данных для генирования шаблонов и $N$ наборов данных для тестирования шаблонов: набор данных для генирования шаблонов $i$ является просто разделом $d_i$, а набор для тестирования -- всем словарем с исключенным разделом $d_i$, т.~е. $\cup_{j \neq i} d_j$. Теперь мы генерируем шаблоны используя каждый из этих $N$ наборов и тестируем эти шаблоны на его наборе для тестирования. Мы измеряем эффективность  $i$-ных шаблонов по определению слогоделения набора для тестирования для каждого из $N$ наборов. Наша задача -- максимизировать среднее значение этой эффективности по $N$ наборам данных (что в статистическом анализе известно как \textenglish{$N$-fold performance}). Так как по построению, $d_i$ и $\cup_{j \neq i} d_j$ содержат разные слова, то мы можем считать, что результаты отражают реальную ситуацию обобщения шаблонов для слов, не включенных в изначальный словарь.

Единственным методологическим затруднением этого подхода является вопрос, следует ли перемешивать слова перед тем, как генерировать наборы слов $d_i$ и $\cup_{j \neq i} d_j$. Мы решили не перемешивать слова, что объясняется следующими соображениями. Словарь содержит слова в алфавитном порядке, причем перечень имеет много однокоренных слов, записанных по порядку, к примеру:

\begin{center}
\begin{churchslavonic}
\begin{tabular}{l}
бо-лѣ́-зней \\
бо-лѣ́-знемъ \\
бо-лѣ́-знен-нѡ \\
бо-лѣ́-знен-ны-ѧ \\
бо-лѣ́-зни \\
\end{tabular}
\end{churchslavonic}
\end{center}

\noindent Если мы перемешаем слова, то в результате и набор генерирования $d_i$, и набор тестирования $\cup_{j \neq i} d_j$ могут содержать однокоренные слова. Однако нас интересует в первую очередь как раз способность шаблонов корректно разделять на слоги новые корни, т.~к. слогоделение суффиксов предсказывается всеми словами словаря и является более надежным, а слогоделения корней только разучивается алгоритмом за счет слов, содержащих этот корень. Если наборы для генерирования и тестирования созданы без перемешивания, то в худшем случае, они могут содержать однокоренные слова на границах наборов, а также однокоренные слова с другими префиксами, напр., \textchurchslavonic{без-бо-лѣ́-знен-нѡ}. Так как мы ограничиваемся $N \leq 4$, то можно предположить, что эффект присутствия однокоренных слов в этих случаях мизерный.

При генерировании шаблонов помимо параметров $good\_wt$, $bad\_wt$ и $threshold$ Формулы~\ref{eff_formula}, мы также можем установить количество уровней шаблонов (от одного до девяти). При этом нечетные уровни дают разрешающие шаблоны, а четные уровни -- запрещающие шаблоны. Эмпирические наблюдения показали, что наличие дополнительных уровней никак не повышает эффективность шаблонов. Таким образом, оптимальным количеством уровней является ровно два: один уровень разрешающих шаблонов и один уровень запрещающих шаблонов. Далее, мы можем контролировать длину шаблонов. Наши наблюдения показали, что разрешающие шаблоны длиной в одну букву приводят к большому количеству ошибок; с другой стороны, очень эффективны запрещающие шаблоны длиной в один символ. Что же касается длинных шаблонов, то шаблоны длиной в более чем четыре символа приводят к большому количеству ошибок. Таким образом мы ограничиваемся разрешающими шаблонами длиной в два, три или четыре символа. Наконец, при выборе параметров отбора шаблонов $good\_wt$, $bad\_wt$ и $threshold$ мы можем контролировать отбор шаблонов либо путем переменной $bad\_wt$, либо переменной $threshold$. На практике оказывается, что лучше всего установить $threshold = 1$ и увеличивать параметр $bad\_wt$.

Итак, мы остановились на двухуровневом наборе шаблонов. Первый уровень создает потенциальные позиции слогоделения, а второй уровень запрещает некоторые из них. При такой схеме, для достижения наилучшего результата требуется, чтобы первый уровень шаблонов находил наибольшее количество правильных точек слогоделения, при этом не предлагая слишком много неправильных точек. С другой стороны, второй уровень должен запрещать как можно больше неправильных точек слогоделения и пропускать практически все правильные. Но поскольку уровни шаблонов в методе Льянга генерируются последовательно, то невозможно создать одновременно хорошие шаблоны и для первого и для второго уровней. Если, например, мы подбираем параметры генерации и получаем очень хороший разрешающий уровень, то для создания второго, запрещающего уровня мы будем иметь слишком мало примеров неправильного слогоделения; в этом случае второму уровню просто не хватит данных для обобщения всех возможных точек неправильного слогоделения и создания качественных шаблонов. Напомним, что мы хотим создать набор шаблонов, который не только хорошо работает на словах из нашего словаря, но и обощается для новых слов. Именно для этого желательно иметь максимально качественные шаблоны как первого, так и второго уровней.

Чтобы достичь высокого качества шаблонов второго уровня мы изобрели следующий прием: после оптимизации параметров для получения наиболее качественного первого уровня, мы искусственно ухудшаем первый уровень с целью значительного увеличения количества неправильных точек слогоделения. И на таких примерах мы генерируем второй уровень, стараясь оптимизаровать эффективность именно второго уровня. После этого окончательный набор шаблонов строится путем комбинирования шаблонов этих двух отдельных генераций: к лучшему результату шаблонов первого уровеня добавляются лучшие результаты шаблонов второго уровеня. Как показала перекрестная проверка, такой метод снижает абсолютный процент ошибок на 1--2\% (что, при общем количестве ошибок около 10\%, является значительным улучшением).

\begin{table}[ht]
\centering
\caption{Результаты перекрестной проверки \label{validation_results}}
\begin{tabular}{cccc}
		&	\multicolumn{2}{c}{процент неправильных слогоделений} & \\
		&	пропущенных		& ошибочных	& F-статистика \\
\hline
$N = 2$	& 	9,6\%			& 	3,1\% 	&	93,5 \\
$N = 3$ 	& 	7,7\%			& 	3,0\% 	& 	94,6	\\
$N = 4$ 	&	7,8\%			& 	2,9\% 	& 	94,6	\\
\hline
\end{tabular}
\end{table}

Мы использовали сценарии, выполняющие перекрестную проверку с $N = 2$, $3$ и $4$ разделами. Результаты представлены в Таблице~\ref{validation_results}. Суммируя количество пропущенных мест для слогоделения и количество неправильных слогоделений при  $N = 3$, общее количество ошибок равно $10,7\%$.  Так как наш словарь содержит $90\%$ самых употребляемых слов церковнославянского языка, для которых алгоритм будет обязательно выдавать правильное слогоделение, то в среднем мы можем ожидать, что для какого-то текста, алгоритм пропустит возможное слогоделение в $0,77\%$  случаев и сделает ошибочное слогоделение в $0,30\%$ случаев. Пропущенное слогоделение будет незаметно для пользователя, так как в этом случае \TeX{} просто выберет другое, менее оптимальное место для переноса. Но ошибочное слогоделение будет нарушать орфографические правила церковнославянского языка и <<резать глаз>>. Если предположить, что случаи появления слова на странице являются независимыми событиями, и что в среднем страница печатного текста содержит около 10 переносов, то мы можем заключить, что риск получить ошибочное слогоделение на какой-то странице равен около $3,0\%$. Этот результат может быть улучшен расширением изначального словаря разделенных по слогам слов.

\section{Заключение}

Необходимые для записи церковнославянского языка символы появились в пятой версии Юникода в 2008~г. Однако долгое время отсутствие шрифтов и утилит затрудняло работу с церковнославянским текстом. Разработанные нами шаблоны переноса строки для системы компьютерной типографики \TeX{} восполняют этот пробел в компьютерных технологиях и позволяют верстать церковнославянский текст в \TeX{} и производных системах \XeTeX{} и \LuaTeX{}. Установив распространяемый нами свободный пакет \texttt{churchslavonic}\footnote{Либо с сайта \url{http://www.ctan.org/pkg/churchslavonic}, либо посредством утилиты tlmgr.}, пользователи могут получить доступ к церковнославянским шрифтам, разработанным шаблонам и ряду дополнительных макрокоманд для церковнославянской типографики. Как мы показали в этой статье, несмотря на ограниченный объем словаря, использованного для генерирования шаблонов, они дают вполне допустимые для компьютерной типографики результаты. Переложение алгоритма слогоделения \TeX{}  существует и в ряде других языков программирования, в том числе Haskell, JavaScript, Perl, Python и Ruby, так что разработанные шаблоны также могут использоваться и в этих средах программирования. Алгоритм используется и рядом программ набора и верстки текста, в том числе свободной программой \verb+LibreOffice+. Нами также разработана надстройка (\verb+extension+) для \verb+LibreOffice 5.0+\footnote{См. \url{http://extensions.libreoffice.org/extension-center/church-slavonic-dictionary}.}, предоставляющая шаблоны переноса для церковнославянского языка, и позволяющая верстать церковнославянский текст и в этом популярном приложении.

\printbibliography

\end{document}
